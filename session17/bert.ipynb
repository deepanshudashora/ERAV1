{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Libs\n",
    "# =============================================================================\n",
    "from torch.utils.data import Dataset\n",
    "import torch.nn.functional as F\n",
    "from collections import Counter\n",
    "from os.path import exists\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "import math\n",
    "import re\n",
    "\n",
    "!git clone https://github.com/deepanshudashora/custom_models.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from custom_models.transformers.model import Transformer\n",
    "from custom_models.transformers.datamodules.bert_datamodule import SentencesDataset,create_sentences_and_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_batch(loader, loader_iter):\n",
    "    try:\n",
    "        batch = next(loader_iter)\n",
    "    except StopIteration:\n",
    "        loader_iter = iter(loader)\n",
    "        batch = next(loader_iter)\n",
    "    return batch, loader_iter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing..\n",
      "loading text...\n",
      "tokenizing sentences...\n",
      "creating/loading vocab...\n",
      "creating dataset...\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# #Init\n",
    "# =============================================================================\n",
    "print('initializing..')\n",
    "batch_size = 1024\n",
    "seq_len = 20\n",
    "embed_size = 128\n",
    "inner_ff_size = embed_size * 4\n",
    "n_heads = 8\n",
    "n_code = 8\n",
    "n_vocab = 40000\n",
    "dropout = 0.1\n",
    "# n_workers = 12\n",
    "\n",
    "optim_kwargs = {'lr':1e-4, 'weight_decay':1e-4, 'betas':(.9,.999)}\n",
    "\n",
    "#1) load text\n",
    "print('loading text...')\n",
    "sentence_path = 'training.txt'\n",
    "vocab_path = \"vocab.txt\"\n",
    "\n",
    "sentences, vocab = create_sentences_and_vocab(sentence_path,vocab_path)\n",
    "print('creating dataset...')\n",
    "dataset = SentencesDataset(sentences, vocab, seq_len)\n",
    "# kwargs = {'num_workers':n_workers, 'shuffle':True,  'drop_last':True, 'pin_memory':True, 'batch_size':batch_size}\n",
    "kwargs = {'shuffle':True,  'drop_last':True, 'pin_memory':True, 'batch_size':batch_size}\n",
    "data_loader = torch.utils.data.DataLoader(dataset, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing model...\n",
      "initializing optimizer and loss...\n",
      "training...\n",
      "it: 0  | loss 10.25  | Δw: 1.215\n",
      "it: 10  | loss 9.6  | Δw: 0.552\n",
      "it: 20  | loss 9.37  | Δw: 0.364\n",
      "it: 30  | loss 9.21  | Δw: 0.277\n",
      "it: 40  | loss 9.06  | Δw: 0.243\n",
      "it: 50  | loss 8.87  | Δw: 0.217\n",
      "it: 60  | loss 8.71  | Δw: 0.201\n",
      "it: 70  | loss 8.59  | Δw: 0.195\n",
      "it: 80  | loss 8.44  | Δw: 0.185\n",
      "it: 90  | loss 8.3  | Δw: 0.172\n",
      "it: 100  | loss 8.13  | Δw: 0.167\n",
      "it: 110  | loss 8.02  | Δw: 0.156\n",
      "it: 120  | loss 7.87  | Δw: 0.153\n",
      "it: 130  | loss 7.72  | Δw: 0.152\n",
      "it: 140  | loss 7.6  | Δw: 0.154\n",
      "it: 150  | loss 7.45  | Δw: 0.148\n",
      "it: 160  | loss 7.35  | Δw: 0.144\n",
      "it: 170  | loss 7.27  | Δw: 0.139\n",
      "it: 180  | loss 7.17  | Δw: 0.146\n",
      "it: 190  | loss 7.06  | Δw: 0.142\n",
      "it: 200  | loss 6.99  | Δw: 0.143\n",
      "it: 210  | loss 6.88  | Δw: 0.149\n",
      "it: 220  | loss 6.75  | Δw: 0.142\n",
      "it: 230  | loss 6.75  | Δw: 0.142\n",
      "it: 240  | loss 6.68  | Δw: 0.152\n",
      "it: 250  | loss 6.61  | Δw: 0.143\n",
      "it: 260  | loss 6.6  | Δw: 0.151\n",
      "it: 270  | loss 6.59  | Δw: 0.151\n",
      "it: 280  | loss 6.58  | Δw: 0.169\n",
      "it: 290  | loss 6.51  | Δw: 0.157\n",
      "it: 300  | loss 6.51  | Δw: 0.166\n",
      "it: 310  | loss 6.43  | Δw: 0.181\n",
      "it: 320  | loss 6.43  | Δw: 0.177\n",
      "it: 330  | loss 6.46  | Δw: 0.187\n",
      "it: 340  | loss 6.4  | Δw: 0.2\n",
      "it: 350  | loss 6.38  | Δw: 0.208\n",
      "it: 360  | loss 6.41  | Δw: 0.211\n",
      "it: 370  | loss 6.4  | Δw: 0.228\n",
      "it: 380  | loss 6.43  | Δw: 0.25\n",
      "it: 390  | loss 6.36  | Δw: 0.307\n",
      "it: 400  | loss 6.36  | Δw: 0.268\n",
      "it: 410  | loss 6.34  | Δw: 0.287\n",
      "it: 420  | loss 6.36  | Δw: 0.32\n",
      "it: 430  | loss 6.39  | Δw: 0.357\n",
      "it: 440  | loss 6.33  | Δw: 0.375\n",
      "it: 450  | loss 6.37  | Δw: 0.474\n",
      "it: 460  | loss 6.38  | Δw: 0.487\n",
      "it: 470  | loss 6.27  | Δw: 0.428\n",
      "it: 480  | loss 6.36  | Δw: 0.453\n",
      "it: 490  | loss 6.31  | Δw: 0.44\n",
      "it: 500  | loss 6.34  | Δw: 0.511\n",
      "it: 510  | loss 6.32  | Δw: 0.508\n",
      "it: 520  | loss 6.31  | Δw: 0.538\n",
      "it: 530  | loss 6.31  | Δw: 0.572\n",
      "it: 540  | loss 6.32  | Δw: 0.586\n",
      "it: 550  | loss 6.28  | Δw: 0.731\n",
      "it: 560  | loss 6.34  | Δw: 0.667\n",
      "it: 570  | loss 6.38  | Δw: 0.696\n",
      "it: 580  | loss 6.3  | Δw: 0.678\n",
      "it: 590  | loss 6.29  | Δw: 0.764\n",
      "it: 600  | loss 6.38  | Δw: 0.711\n",
      "it: 610  | loss 6.24  | Δw: 0.846\n",
      "it: 620  | loss 6.25  | Δw: 0.782\n",
      "it: 630  | loss 6.31  | Δw: 0.797\n",
      "it: 640  | loss 6.26  | Δw: 0.834\n",
      "it: 650  | loss 6.26  | Δw: 0.822\n",
      "it: 660  | loss 6.24  | Δw: 0.922\n",
      "it: 670  | loss 6.18  | Δw: 0.942\n",
      "it: 680  | loss 6.29  | Δw: 0.944\n",
      "it: 690  | loss 6.26  | Δw: 0.987\n",
      "it: 700  | loss 6.3  | Δw: 0.953\n",
      "it: 710  | loss 6.28  | Δw: 1.024\n",
      "it: 720  | loss 6.3  | Δw: 1.003\n",
      "it: 730  | loss 6.2  | Δw: 1.062\n",
      "it: 740  | loss 6.2  | Δw: 1.116\n",
      "it: 750  | loss 6.11  | Δw: 1.067\n",
      "it: 760  | loss 6.22  | Δw: 1.159\n",
      "it: 770  | loss 6.23  | Δw: 1.124\n",
      "it: 780  | loss 6.2  | Δw: 1.273\n",
      "it: 790  | loss 6.2  | Δw: 1.202\n",
      "it: 800  | loss 6.22  | Δw: 1.18\n",
      "it: 810  | loss 6.28  | Δw: 1.283\n",
      "it: 820  | loss 6.15  | Δw: 1.367\n",
      "it: 830  | loss 6.2  | Δw: 1.306\n",
      "it: 840  | loss 6.12  | Δw: 1.212\n",
      "it: 850  | loss 6.22  | Δw: 1.361\n",
      "it: 860  | loss 6.17  | Δw: 1.443\n",
      "it: 870  | loss 6.15  | Δw: 1.462\n",
      "it: 880  | loss 6.23  | Δw: 1.377\n",
      "it: 890  | loss 6.2  | Δw: 1.356\n",
      "it: 900  | loss 6.12  | Δw: 1.459\n",
      "it: 910  | loss 6.16  | Δw: 1.397\n",
      "it: 920  | loss 6.21  | Δw: 1.539\n",
      "it: 930  | loss 6.18  | Δw: 1.524\n",
      "it: 940  | loss 6.15  | Δw: 1.53\n",
      "it: 950  | loss 6.15  | Δw: 1.635\n",
      "it: 960  | loss 6.19  | Δw: 1.647\n",
      "it: 970  | loss 6.21  | Δw: 1.595\n",
      "it: 980  | loss 6.08  | Δw: 1.655\n",
      "it: 990  | loss 6.09  | Δw: 1.585\n",
      "it: 1000  | loss 6.05  | Δw: 1.63\n",
      "it: 1010  | loss 6.12  | Δw: 1.625\n",
      "it: 1020  | loss 6.09  | Δw: 1.709\n",
      "it: 1030  | loss 6.06  | Δw: 1.834\n",
      "it: 1040  | loss 6.04  | Δw: 1.834\n",
      "it: 1050  | loss 6.14  | Δw: 1.885\n",
      "it: 1060  | loss 6.01  | Δw: 2.112\n",
      "it: 1070  | loss 6.1  | Δw: 1.887\n",
      "it: 1080  | loss 5.97  | Δw: 2.109\n",
      "it: 1090  | loss 5.96  | Δw: 2.019\n",
      "it: 1100  | loss 6.06  | Δw: 2.068\n",
      "it: 1110  | loss 6.09  | Δw: 1.953\n",
      "it: 1120  | loss 6.0  | Δw: 1.98\n",
      "it: 1130  | loss 5.89  | Δw: 2.121\n",
      "it: 1140  | loss 5.93  | Δw: 2.061\n",
      "it: 1150  | loss 6.07  | Δw: 2.136\n",
      "it: 1160  | loss 5.96  | Δw: 2.181\n",
      "it: 1170  | loss 5.98  | Δw: 2.076\n",
      "it: 1180  | loss 5.98  | Δw: 2.194\n",
      "it: 1190  | loss 5.93  | Δw: 2.153\n",
      "it: 1200  | loss 6.02  | Δw: 2.3\n",
      "it: 1210  | loss 5.81  | Δw: 2.348\n",
      "it: 1220  | loss 5.89  | Δw: 2.302\n",
      "it: 1230  | loss 5.89  | Δw: 2.339\n",
      "it: 1240  | loss 5.89  | Δw: 2.387\n",
      "it: 1250  | loss 5.98  | Δw: 2.414\n",
      "it: 1260  | loss 5.95  | Δw: 2.435\n",
      "it: 1270  | loss 6.04  | Δw: 2.516\n",
      "it: 1280  | loss 6.01  | Δw: 2.647\n",
      "it: 1290  | loss 5.91  | Δw: 2.451\n",
      "it: 1300  | loss 5.93  | Δw: 2.907\n",
      "it: 1310  | loss 5.89  | Δw: 2.63\n",
      "it: 1320  | loss 5.95  | Δw: 2.712\n",
      "it: 1330  | loss 5.88  | Δw: 2.499\n",
      "it: 1340  | loss 5.9  | Δw: 2.526\n",
      "it: 1350  | loss 5.84  | Δw: 2.656\n",
      "it: 1360  | loss 5.95  | Δw: 2.674\n",
      "it: 1370  | loss 5.8  | Δw: 2.813\n",
      "it: 1380  | loss 5.89  | Δw: 2.863\n",
      "it: 1390  | loss 5.84  | Δw: 2.86\n",
      "it: 1400  | loss 5.81  | Δw: 3.013\n",
      "it: 1410  | loss 5.83  | Δw: 2.926\n",
      "it: 1420  | loss 5.86  | Δw: 2.819\n",
      "it: 1430  | loss 5.69  | Δw: 2.929\n",
      "it: 1440  | loss 5.83  | Δw: 3.043\n",
      "it: 1450  | loss 5.81  | Δw: 2.959\n",
      "it: 1460  | loss 5.81  | Δw: 2.961\n",
      "it: 1470  | loss 5.85  | Δw: 3.001\n",
      "it: 1480  | loss 5.84  | Δw: 3.062\n",
      "it: 1490  | loss 5.94  | Δw: 3.025\n",
      "it: 1500  | loss 5.73  | Δw: 3.149\n",
      "it: 1510  | loss 5.84  | Δw: 3.086\n",
      "it: 1520  | loss 5.88  | Δw: 3.148\n",
      "it: 1530  | loss 5.73  | Δw: 3.275\n",
      "it: 1540  | loss 5.79  | Δw: 3.141\n",
      "it: 1550  | loss 5.81  | Δw: 3.207\n",
      "it: 1560  | loss 5.78  | Δw: 3.195\n",
      "it: 1570  | loss 5.71  | Δw: 3.545\n",
      "it: 1580  | loss 5.76  | Δw: 3.552\n",
      "it: 1590  | loss 5.81  | Δw: 3.381\n",
      "it: 1600  | loss 5.79  | Δw: 3.283\n",
      "it: 1610  | loss 5.61  | Δw: 3.28\n",
      "it: 1620  | loss 5.67  | Δw: 3.414\n",
      "it: 1630  | loss 5.73  | Δw: 3.404\n",
      "it: 1640  | loss 5.76  | Δw: 3.43\n",
      "it: 1650  | loss 5.74  | Δw: 3.559\n",
      "it: 1660  | loss 5.76  | Δw: 3.433\n",
      "it: 1670  | loss 5.75  | Δw: 3.355\n",
      "it: 1680  | loss 5.73  | Δw: 3.381\n",
      "it: 1690  | loss 5.78  | Δw: 3.46\n",
      "it: 1700  | loss 5.64  | Δw: 3.448\n",
      "it: 1710  | loss 5.65  | Δw: 3.662\n",
      "it: 1720  | loss 5.75  | Δw: 3.733\n",
      "it: 1730  | loss 5.6  | Δw: 3.586\n",
      "it: 1740  | loss 5.61  | Δw: 3.887\n",
      "it: 1750  | loss 5.64  | Δw: 3.5\n",
      "it: 1760  | loss 5.75  | Δw: 3.659\n",
      "it: 1770  | loss 5.68  | Δw: 3.863\n",
      "it: 1780  | loss 5.64  | Δw: 4.067\n",
      "it: 1790  | loss 5.63  | Δw: 3.834\n",
      "it: 1800  | loss 5.67  | Δw: 3.643\n",
      "it: 1810  | loss 5.66  | Δw: 3.848\n",
      "it: 1820  | loss 5.59  | Δw: 3.657\n",
      "it: 1830  | loss 5.6  | Δw: 4.061\n",
      "it: 1840  | loss 5.61  | Δw: 3.741\n",
      "it: 1850  | loss 5.59  | Δw: 3.77\n",
      "it: 1860  | loss 5.5  | Δw: 3.929\n",
      "it: 1870  | loss 5.52  | Δw: 3.801\n",
      "it: 1880  | loss 5.61  | Δw: 4.175\n",
      "it: 1890  | loss 5.59  | Δw: 3.899\n",
      "it: 1900  | loss 5.55  | Δw: 3.835\n",
      "it: 1910  | loss 5.58  | Δw: 4.004\n",
      "it: 1920  | loss 5.57  | Δw: 3.79\n",
      "it: 1930  | loss 5.53  | Δw: 3.84\n",
      "it: 1940  | loss 5.47  | Δw: 4.104\n",
      "it: 1950  | loss 5.57  | Δw: 4.133\n",
      "it: 1960  | loss 5.53  | Δw: 4.101\n",
      "it: 1970  | loss 5.49  | Δw: 4.02\n",
      "it: 1980  | loss 5.52  | Δw: 4.128\n",
      "it: 1990  | loss 5.53  | Δw: 3.991\n",
      "it: 2000  | loss 5.56  | Δw: 3.975\n",
      "it: 2010  | loss 5.56  | Δw: 4.26\n",
      "it: 2020  | loss 5.59  | Δw: 4.067\n",
      "it: 2030  | loss 5.49  | Δw: 4.28\n",
      "it: 2040  | loss 5.53  | Δw: 4.308\n",
      "it: 2050  | loss 5.59  | Δw: 4.251\n",
      "it: 2060  | loss 5.61  | Δw: 4.087\n",
      "it: 2070  | loss 5.58  | Δw: 4.182\n",
      "it: 2080  | loss 5.44  | Δw: 4.304\n",
      "it: 2090  | loss 5.51  | Δw: 4.302\n",
      "it: 2100  | loss 5.45  | Δw: 4.117\n",
      "it: 2110  | loss 5.41  | Δw: 4.199\n",
      "it: 2120  | loss 5.55  | Δw: 4.341\n",
      "it: 2130  | loss 5.54  | Δw: 4.499\n",
      "it: 2140  | loss 5.49  | Δw: 4.379\n",
      "it: 2150  | loss 5.53  | Δw: 4.51\n",
      "it: 2160  | loss 5.52  | Δw: 4.377\n",
      "it: 2170  | loss 5.42  | Δw: 4.68\n",
      "it: 2180  | loss 5.48  | Δw: 4.272\n",
      "it: 2190  | loss 5.45  | Δw: 4.435\n",
      "it: 2200  | loss 5.47  | Δw: 4.282\n",
      "it: 2210  | loss 5.39  | Δw: 4.538\n",
      "it: 2220  | loss 5.44  | Δw: 4.57\n",
      "it: 2230  | loss 5.38  | Δw: 4.621\n",
      "it: 2240  | loss 5.4  | Δw: 4.602\n",
      "it: 2250  | loss 5.43  | Δw: 4.447\n",
      "it: 2260  | loss 5.44  | Δw: 4.692\n",
      "it: 2270  | loss 5.37  | Δw: 4.636\n",
      "it: 2280  | loss 5.3  | Δw: 4.511\n",
      "it: 2290  | loss 5.42  | Δw: 4.42\n",
      "it: 2300  | loss 5.41  | Δw: 4.819\n",
      "it: 2310  | loss 5.38  | Δw: 4.54\n",
      "it: 2320  | loss 5.47  | Δw: 4.873\n",
      "it: 2330  | loss 5.37  | Δw: 5.03\n",
      "it: 2340  | loss 5.29  | Δw: 5.087\n",
      "it: 2350  | loss 5.42  | Δw: 4.955\n",
      "it: 2360  | loss 5.28  | Δw: 4.944\n",
      "it: 2370  | loss 5.29  | Δw: 4.885\n",
      "it: 2380  | loss 5.42  | Δw: 4.639\n",
      "it: 2390  | loss 5.36  | Δw: 4.998\n",
      "it: 2400  | loss 5.38  | Δw: 4.836\n",
      "it: 2410  | loss 5.43  | Δw: 4.868\n",
      "it: 2420  | loss 5.39  | Δw: 4.663\n",
      "it: 2430  | loss 5.32  | Δw: 4.728\n",
      "it: 2440  | loss 5.27  | Δw: 4.719\n",
      "it: 2450  | loss 5.38  | Δw: 5.015\n",
      "it: 2460  | loss 5.23  | Δw: 4.987\n",
      "it: 2470  | loss 5.41  | Δw: 5.001\n",
      "it: 2480  | loss 5.42  | Δw: 5.033\n",
      "it: 2490  | loss 5.36  | Δw: 5.099\n",
      "it: 2500  | loss 5.24  | Δw: 4.854\n",
      "it: 2510  | loss 5.29  | Δw: 5.165\n",
      "it: 2520  | loss 5.24  | Δw: 4.705\n",
      "it: 2530  | loss 5.36  | Δw: 4.878\n",
      "it: 2540  | loss 5.39  | Δw: 4.723\n",
      "it: 2550  | loss 5.29  | Δw: 5.037\n",
      "it: 2560  | loss 5.31  | Δw: 4.897\n",
      "it: 2570  | loss 5.21  | Δw: 5.203\n",
      "it: 2580  | loss 5.26  | Δw: 5.183\n",
      "it: 2590  | loss 5.27  | Δw: 4.831\n",
      "it: 2600  | loss 5.2  | Δw: 5.433\n",
      "it: 2610  | loss 5.33  | Δw: 4.951\n",
      "it: 2620  | loss 5.25  | Δw: 5.19\n",
      "it: 2630  | loss 5.25  | Δw: 5.068\n",
      "it: 2640  | loss 5.32  | Δw: 5.087\n",
      "it: 2650  | loss 5.11  | Δw: 5.202\n",
      "it: 2660  | loss 5.3  | Δw: 5.248\n",
      "it: 2670  | loss 5.07  | Δw: 4.919\n",
      "it: 2680  | loss 5.26  | Δw: 5.217\n",
      "it: 2690  | loss 5.22  | Δw: 5.052\n",
      "it: 2700  | loss 5.28  | Δw: 5.257\n",
      "it: 2710  | loss 5.31  | Δw: 4.993\n",
      "it: 2720  | loss 5.2  | Δw: 5.468\n",
      "it: 2730  | loss 5.18  | Δw: 5.303\n",
      "it: 2740  | loss 5.26  | Δw: 5.204\n",
      "it: 2750  | loss 5.2  | Δw: 5.057\n",
      "it: 2760  | loss 5.25  | Δw: 5.193\n",
      "it: 2770  | loss 5.14  | Δw: 5.262\n",
      "it: 2780  | loss 5.18  | Δw: 5.231\n",
      "it: 2790  | loss 5.13  | Δw: 4.983\n",
      "it: 2800  | loss 5.06  | Δw: 5.054\n",
      "it: 2810  | loss 5.16  | Δw: 5.253\n",
      "it: 2820  | loss 5.15  | Δw: 5.475\n",
      "it: 2830  | loss 5.19  | Δw: 5.585\n",
      "it: 2840  | loss 5.21  | Δw: 5.47\n",
      "it: 2850  | loss 5.16  | Δw: 5.374\n",
      "it: 2860  | loss 5.29  | Δw: 5.6\n",
      "it: 2870  | loss 5.14  | Δw: 5.387\n",
      "it: 2880  | loss 5.19  | Δw: 5.3\n",
      "it: 2890  | loss 5.05  | Δw: 5.099\n",
      "it: 2900  | loss 5.13  | Δw: 5.494\n",
      "it: 2910  | loss 5.23  | Δw: 5.254\n",
      "it: 2920  | loss 5.2  | Δw: 5.443\n",
      "it: 2930  | loss 5.0  | Δw: 5.21\n",
      "it: 2940  | loss 5.24  | Δw: 5.427\n",
      "it: 2950  | loss 5.21  | Δw: 5.401\n",
      "it: 2960  | loss 5.19  | Δw: 5.338\n",
      "it: 2970  | loss 5.22  | Δw: 5.57\n",
      "it: 2980  | loss 5.11  | Δw: 5.232\n",
      "it: 2990  | loss 5.14  | Δw: 5.446\n",
      "it: 3000  | loss 5.09  | Δw: 5.528\n",
      "it: 3010  | loss 5.1  | Δw: 5.352\n",
      "it: 3020  | loss 5.2  | Δw: 5.71\n",
      "it: 3030  | loss 4.99  | Δw: 5.64\n",
      "it: 3040  | loss 5.17  | Δw: 5.282\n",
      "it: 3050  | loss 5.02  | Δw: 5.618\n",
      "it: 3060  | loss 5.08  | Δw: 5.305\n",
      "it: 3070  | loss 5.19  | Δw: 5.575\n",
      "it: 3080  | loss 5.06  | Δw: 5.493\n",
      "it: 3090  | loss 5.09  | Δw: 5.698\n",
      "it: 3100  | loss 5.14  | Δw: 5.268\n",
      "it: 3110  | loss 5.08  | Δw: 5.591\n",
      "it: 3120  | loss 5.0  | Δw: 5.35\n",
      "it: 3130  | loss 5.09  | Δw: 5.649\n",
      "it: 3140  | loss 5.02  | Δw: 6.052\n",
      "it: 3150  | loss 5.08  | Δw: 5.324\n",
      "it: 3160  | loss 5.09  | Δw: 5.568\n",
      "it: 3170  | loss 5.09  | Δw: 5.467\n",
      "it: 3180  | loss 5.1  | Δw: 5.85\n",
      "it: 3190  | loss 5.14  | Δw: 5.661\n",
      "it: 3200  | loss 5.14  | Δw: 5.757\n",
      "it: 3210  | loss 5.07  | Δw: 5.967\n",
      "it: 3220  | loss 5.09  | Δw: 5.959\n",
      "it: 3230  | loss 5.17  | Δw: 5.701\n",
      "it: 3240  | loss 5.05  | Δw: 5.543\n",
      "it: 3250  | loss 5.17  | Δw: 5.684\n",
      "it: 3260  | loss 4.96  | Δw: 5.759\n",
      "it: 3270  | loss 5.04  | Δw: 5.345\n",
      "it: 3280  | loss 4.99  | Δw: 5.846\n",
      "it: 3290  | loss 5.01  | Δw: 5.805\n",
      "it: 3300  | loss 4.96  | Δw: 5.983\n",
      "it: 3310  | loss 4.96  | Δw: 5.845\n",
      "it: 3320  | loss 4.92  | Δw: 5.572\n",
      "it: 3330  | loss 5.01  | Δw: 5.695\n",
      "it: 3340  | loss 4.91  | Δw: 5.771\n",
      "it: 3350  | loss 5.0  | Δw: 5.739\n",
      "it: 3360  | loss 5.06  | Δw: 5.609\n",
      "it: 3370  | loss 4.99  | Δw: 5.926\n",
      "it: 3380  | loss 5.08  | Δw: 6.099\n",
      "it: 3390  | loss 4.93  | Δw: 6.074\n",
      "it: 3400  | loss 4.95  | Δw: 5.989\n",
      "it: 3410  | loss 5.0  | Δw: 5.918\n",
      "it: 3420  | loss 5.05  | Δw: 5.652\n",
      "it: 3430  | loss 4.97  | Δw: 5.796\n",
      "it: 3440  | loss 5.1  | Δw: 5.596\n",
      "it: 3450  | loss 5.03  | Δw: 5.982\n",
      "it: 3460  | loss 4.99  | Δw: 6.128\n",
      "it: 3470  | loss 5.08  | Δw: 6.134\n",
      "it: 3480  | loss 5.01  | Δw: 5.507\n",
      "it: 3490  | loss 5.03  | Δw: 6.095\n",
      "it: 3500  | loss 4.92  | Δw: 6.079\n",
      "it: 3510  | loss 4.95  | Δw: 5.568\n",
      "it: 3520  | loss 4.97  | Δw: 5.947\n",
      "it: 3530  | loss 5.0  | Δw: 5.886\n",
      "it: 3540  | loss 5.0  | Δw: 5.86\n",
      "it: 3550  | loss 4.92  | Δw: 6.032\n",
      "it: 3560  | loss 4.96  | Δw: 6.012\n",
      "it: 3570  | loss 4.89  | Δw: 6.009\n",
      "it: 3580  | loss 4.93  | Δw: 5.963\n",
      "it: 3590  | loss 4.98  | Δw: 6.07\n",
      "it: 3600  | loss 4.89  | Δw: 5.896\n",
      "it: 3610  | loss 4.91  | Δw: 6.217\n",
      "it: 3620  | loss 5.04  | Δw: 5.722\n",
      "it: 3630  | loss 4.99  | Δw: 5.893\n",
      "it: 3640  | loss 4.96  | Δw: 5.955\n",
      "it: 3650  | loss 4.97  | Δw: 5.89\n",
      "it: 3660  | loss 5.03  | Δw: 5.938\n",
      "it: 3670  | loss 4.94  | Δw: 6.036\n",
      "it: 3680  | loss 5.02  | Δw: 6.035\n",
      "it: 3690  | loss 5.02  | Δw: 5.867\n",
      "it: 3700  | loss 4.96  | Δw: 6.035\n",
      "it: 3710  | loss 5.05  | Δw: 5.733\n",
      "it: 3720  | loss 4.85  | Δw: 5.815\n",
      "it: 3730  | loss 4.89  | Δw: 5.898\n",
      "it: 3740  | loss 4.91  | Δw: 5.937\n",
      "it: 3750  | loss 4.84  | Δw: 6.243\n",
      "it: 3760  | loss 5.03  | Δw: 6.159\n",
      "it: 3770  | loss 4.91  | Δw: 5.682\n",
      "it: 3780  | loss 4.9  | Δw: 5.842\n",
      "it: 3790  | loss 4.97  | Δw: 5.819\n",
      "it: 3800  | loss 4.87  | Δw: 5.915\n",
      "it: 3810  | loss 4.9  | Δw: 5.956\n",
      "it: 3820  | loss 4.93  | Δw: 6.242\n",
      "it: 3830  | loss 4.9  | Δw: 6.013\n",
      "it: 3840  | loss 4.83  | Δw: 6.087\n",
      "it: 3850  | loss 4.86  | Δw: 6.017\n",
      "it: 3860  | loss 4.97  | Δw: 6.169\n",
      "it: 3870  | loss 4.97  | Δw: 6.371\n",
      "it: 3880  | loss 4.99  | Δw: 6.02\n",
      "it: 3890  | loss 4.86  | Δw: 6.002\n",
      "it: 3900  | loss 4.9  | Δw: 6.072\n",
      "it: 3910  | loss 4.8  | Δw: 6.053\n",
      "it: 3920  | loss 4.92  | Δw: 6.157\n",
      "it: 3930  | loss 4.96  | Δw: 6.314\n",
      "it: 3940  | loss 4.91  | Δw: 6.307\n",
      "it: 3950  | loss 4.9  | Δw: 6.07\n",
      "it: 3960  | loss 4.81  | Δw: 5.95\n",
      "it: 3970  | loss 4.87  | Δw: 6.349\n",
      "it: 3980  | loss 4.88  | Δw: 5.824\n",
      "it: 3990  | loss 4.88  | Δw: 6.266\n",
      "it: 4000  | loss 4.89  | Δw: 6.012\n",
      "it: 4010  | loss 4.83  | Δw: 6.1\n",
      "it: 4020  | loss 4.85  | Δw: 6.156\n",
      "it: 4030  | loss 4.89  | Δw: 6.012\n",
      "it: 4040  | loss 4.79  | Δw: 6.333\n",
      "it: 4050  | loss 4.91  | Δw: 6.434\n",
      "it: 4060  | loss 4.9  | Δw: 6.124\n",
      "it: 4070  | loss 4.8  | Δw: 6.363\n",
      "it: 4080  | loss 4.78  | Δw: 6.205\n",
      "it: 4090  | loss 4.9  | Δw: 6.295\n",
      "it: 4100  | loss 4.92  | Δw: 6.373\n",
      "it: 4110  | loss 4.87  | Δw: 6.48\n",
      "it: 4120  | loss 4.91  | Δw: 6.065\n",
      "it: 4130  | loss 4.89  | Δw: 6.41\n",
      "it: 4140  | loss 4.76  | Δw: 6.542\n",
      "it: 4150  | loss 4.87  | Δw: 6.189\n",
      "it: 4160  | loss 4.79  | Δw: 6.384\n",
      "it: 4170  | loss 4.74  | Δw: 6.523\n",
      "it: 4180  | loss 4.77  | Δw: 6.32\n",
      "it: 4190  | loss 4.82  | Δw: 6.253\n",
      "it: 4200  | loss 4.94  | Δw: 6.357\n",
      "it: 4210  | loss 4.81  | Δw: 6.478\n",
      "it: 4220  | loss 4.88  | Δw: 6.265\n",
      "it: 4230  | loss 4.85  | Δw: 6.701\n",
      "it: 4240  | loss 4.86  | Δw: 6.411\n",
      "it: 4250  | loss 4.83  | Δw: 6.323\n",
      "it: 4260  | loss 4.77  | Δw: 6.387\n",
      "it: 4270  | loss 4.9  | Δw: 6.189\n",
      "it: 4280  | loss 4.74  | Δw: 6.229\n",
      "it: 4290  | loss 4.86  | Δw: 6.243\n",
      "it: 4300  | loss 4.75  | Δw: 6.293\n",
      "it: 4310  | loss 4.86  | Δw: 6.39\n",
      "it: 4320  | loss 4.9  | Δw: 6.439\n",
      "it: 4330  | loss 4.83  | Δw: 6.637\n",
      "it: 4340  | loss 4.81  | Δw: 6.357\n",
      "it: 4350  | loss 4.88  | Δw: 6.456\n",
      "it: 4360  | loss 4.78  | Δw: 6.249\n",
      "it: 4370  | loss 4.9  | Δw: 6.147\n",
      "it: 4380  | loss 4.97  | Δw: 6.596\n",
      "it: 4390  | loss 4.77  | Δw: 6.387\n",
      "it: 4400  | loss 4.84  | Δw: 6.639\n",
      "it: 4410  | loss 4.83  | Δw: 6.337\n",
      "it: 4420  | loss 4.83  | Δw: 6.167\n",
      "it: 4430  | loss 4.86  | Δw: 6.731\n",
      "it: 4440  | loss 4.78  | Δw: 6.619\n",
      "it: 4450  | loss 4.78  | Δw: 6.556\n",
      "it: 4460  | loss 4.9  | Δw: 6.331\n",
      "it: 4470  | loss 4.73  | Δw: 6.627\n",
      "it: 4480  | loss 4.8  | Δw: 6.502\n",
      "it: 4490  | loss 4.93  | Δw: 6.653\n",
      "it: 4500  | loss 4.87  | Δw: 6.654\n",
      "it: 4510  | loss 4.72  | Δw: 6.377\n",
      "it: 4520  | loss 4.8  | Δw: 6.338\n",
      "it: 4530  | loss 4.87  | Δw: 6.578\n",
      "it: 4540  | loss 4.79  | Δw: 6.748\n",
      "it: 4550  | loss 4.77  | Δw: 6.461\n",
      "it: 4560  | loss 4.74  | Δw: 6.744\n",
      "it: 4570  | loss 4.76  | Δw: 6.424\n",
      "it: 4580  | loss 4.82  | Δw: 6.44\n",
      "it: 4590  | loss 4.87  | Δw: 6.255\n",
      "it: 4600  | loss 4.75  | Δw: 6.436\n",
      "it: 4610  | loss 4.74  | Δw: 6.436\n",
      "it: 4620  | loss 4.77  | Δw: 6.607\n",
      "it: 4630  | loss 4.76  | Δw: 6.855\n",
      "it: 4640  | loss 4.72  | Δw: 6.402\n",
      "it: 4650  | loss 4.78  | Δw: 6.619\n",
      "it: 4660  | loss 4.69  | Δw: 6.656\n",
      "it: 4670  | loss 4.65  | Δw: 6.561\n",
      "it: 4680  | loss 4.73  | Δw: 6.368\n",
      "it: 4690  | loss 4.73  | Δw: 6.724\n",
      "it: 4700  | loss 4.7  | Δw: 6.459\n",
      "it: 4710  | loss 4.84  | Δw: 6.673\n",
      "it: 4720  | loss 4.81  | Δw: 6.962\n",
      "it: 4730  | loss 4.8  | Δw: 6.652\n",
      "it: 4740  | loss 4.75  | Δw: 6.567\n",
      "it: 4750  | loss 4.8  | Δw: 6.7\n",
      "it: 4760  | loss 4.72  | Δw: 6.702\n",
      "it: 4770  | loss 4.82  | Δw: 6.616\n",
      "it: 4780  | loss 4.75  | Δw: 6.454\n",
      "it: 4790  | loss 4.62  | Δw: 6.993\n",
      "it: 4800  | loss 4.79  | Δw: 6.648\n",
      "it: 4810  | loss 4.74  | Δw: 6.672\n",
      "it: 4820  | loss 4.77  | Δw: 6.768\n",
      "it: 4830  | loss 4.76  | Δw: 6.663\n",
      "it: 4840  | loss 4.72  | Δw: 6.554\n",
      "it: 4850  | loss 4.66  | Δw: 6.751\n",
      "it: 4860  | loss 4.73  | Δw: 6.638\n",
      "it: 4870  | loss 4.72  | Δw: 6.869\n",
      "it: 4880  | loss 4.67  | Δw: 6.855\n",
      "it: 4890  | loss 4.78  | Δw: 6.872\n",
      "it: 4900  | loss 4.71  | Δw: 6.916\n",
      "it: 4910  | loss 4.62  | Δw: 6.534\n",
      "it: 4920  | loss 4.71  | Δw: 7.025\n",
      "it: 4930  | loss 4.67  | Δw: 7.176\n",
      "it: 4940  | loss 4.87  | Δw: 6.598\n",
      "it: 4950  | loss 4.74  | Δw: 6.712\n",
      "it: 4960  | loss 4.77  | Δw: 6.791\n",
      "it: 4970  | loss 4.71  | Δw: 6.573\n",
      "it: 4980  | loss 4.85  | Δw: 6.75\n",
      "it: 4990  | loss 4.6  | Δw: 6.734\n",
      "it: 5000  | loss 4.69  | Δw: 6.746\n",
      "it: 5010  | loss 4.81  | Δw: 6.841\n",
      "it: 5020  | loss 4.76  | Δw: 6.704\n",
      "it: 5030  | loss 4.71  | Δw: 6.948\n",
      "it: 5040  | loss 4.65  | Δw: 7.115\n",
      "it: 5050  | loss 4.71  | Δw: 6.859\n",
      "it: 5060  | loss 4.67  | Δw: 7.104\n",
      "it: 5070  | loss 4.64  | Δw: 7.041\n",
      "it: 5080  | loss 4.69  | Δw: 6.814\n",
      "it: 5090  | loss 4.73  | Δw: 6.884\n",
      "it: 5100  | loss 4.71  | Δw: 6.855\n",
      "it: 5110  | loss 4.77  | Δw: 6.739\n",
      "it: 5120  | loss 4.65  | Δw: 6.986\n",
      "it: 5130  | loss 4.68  | Δw: 6.664\n",
      "it: 5140  | loss 4.69  | Δw: 7.053\n",
      "it: 5150  | loss 4.7  | Δw: 6.895\n",
      "it: 5160  | loss 4.71  | Δw: 6.937\n",
      "it: 5170  | loss 4.71  | Δw: 7.121\n",
      "it: 5180  | loss 4.56  | Δw: 6.919\n",
      "it: 5190  | loss 4.62  | Δw: 6.939\n",
      "it: 5200  | loss 4.55  | Δw: 6.654\n",
      "it: 5210  | loss 4.69  | Δw: 6.68\n",
      "it: 5220  | loss 4.83  | Δw: 6.955\n",
      "it: 5230  | loss 4.67  | Δw: 6.505\n",
      "it: 5240  | loss 4.73  | Δw: 6.794\n",
      "it: 5250  | loss 4.7  | Δw: 6.895\n",
      "it: 5260  | loss 4.59  | Δw: 7.243\n",
      "it: 5270  | loss 4.71  | Δw: 7.441\n",
      "it: 5280  | loss 4.7  | Δw: 6.891\n",
      "it: 5290  | loss 4.7  | Δw: 6.94\n",
      "it: 5300  | loss 4.72  | Δw: 6.961\n",
      "it: 5310  | loss 4.79  | Δw: 7.453\n",
      "it: 5320  | loss 4.69  | Δw: 7.204\n",
      "it: 5330  | loss 4.71  | Δw: 6.757\n",
      "it: 5340  | loss 4.59  | Δw: 6.879\n",
      "it: 5350  | loss 4.69  | Δw: 6.77\n",
      "it: 5360  | loss 4.62  | Δw: 7.43\n",
      "it: 5370  | loss 4.55  | Δw: 7.101\n",
      "it: 5380  | loss 4.67  | Δw: 6.812\n",
      "it: 5390  | loss 4.52  | Δw: 7.199\n",
      "it: 5400  | loss 4.67  | Δw: 6.893\n",
      "it: 5410  | loss 4.66  | Δw: 6.995\n",
      "it: 5420  | loss 4.59  | Δw: 7.058\n",
      "it: 5430  | loss 4.58  | Δw: 7.073\n",
      "it: 5440  | loss 4.69  | Δw: 7.148\n",
      "it: 5450  | loss 4.68  | Δw: 7.311\n",
      "it: 5460  | loss 4.71  | Δw: 7.157\n",
      "it: 5470  | loss 4.68  | Δw: 6.931\n",
      "it: 5480  | loss 4.66  | Δw: 7.514\n",
      "it: 5490  | loss 4.71  | Δw: 6.954\n",
      "it: 5500  | loss 4.72  | Δw: 7.378\n",
      "it: 5510  | loss 4.76  | Δw: 7.167\n",
      "it: 5520  | loss 4.66  | Δw: 6.859\n",
      "it: 5530  | loss 4.74  | Δw: 7.124\n",
      "it: 5540  | loss 4.69  | Δw: 7.162\n",
      "it: 5550  | loss 4.65  | Δw: 7.091\n",
      "it: 5560  | loss 4.61  | Δw: 7.323\n",
      "it: 5570  | loss 4.59  | Δw: 7.152\n",
      "it: 5580  | loss 4.61  | Δw: 7.141\n",
      "it: 5590  | loss 4.6  | Δw: 7.031\n",
      "it: 5600  | loss 4.58  | Δw: 7.546\n",
      "it: 5610  | loss 4.58  | Δw: 7.169\n",
      "it: 5620  | loss 4.66  | Δw: 7.172\n",
      "it: 5630  | loss 4.47  | Δw: 6.955\n",
      "it: 5640  | loss 4.63  | Δw: 7.446\n",
      "it: 5650  | loss 4.69  | Δw: 7.191\n",
      "it: 5660  | loss 4.79  | Δw: 7.095\n",
      "it: 5670  | loss 4.66  | Δw: 7.206\n",
      "it: 5680  | loss 4.69  | Δw: 7.162\n",
      "it: 5690  | loss 4.53  | Δw: 7.419\n",
      "it: 5700  | loss 4.65  | Δw: 7.549\n",
      "it: 5710  | loss 4.62  | Δw: 7.266\n",
      "it: 5720  | loss 4.56  | Δw: 7.271\n",
      "it: 5730  | loss 4.67  | Δw: 7.591\n",
      "it: 5740  | loss 4.64  | Δw: 7.254\n",
      "it: 5750  | loss 4.51  | Δw: 7.427\n",
      "it: 5760  | loss 4.51  | Δw: 7.432\n",
      "it: 5770  | loss 4.63  | Δw: 7.275\n",
      "it: 5780  | loss 4.76  | Δw: 7.291\n",
      "it: 5790  | loss 4.72  | Δw: 7.363\n",
      "it: 5800  | loss 4.62  | Δw: 7.371\n",
      "it: 5810  | loss 4.64  | Δw: 7.276\n",
      "it: 5820  | loss 4.61  | Δw: 7.427\n",
      "it: 5830  | loss 4.46  | Δw: 7.026\n",
      "it: 5840  | loss 4.72  | Δw: 7.462\n",
      "it: 5850  | loss 4.55  | Δw: 7.374\n",
      "it: 5860  | loss 4.65  | Δw: 7.444\n",
      "it: 5870  | loss 4.64  | Δw: 7.393\n",
      "it: 5880  | loss 4.66  | Δw: 7.484\n",
      "it: 5890  | loss 4.63  | Δw: 7.443\n",
      "it: 5900  | loss 4.56  | Δw: 7.54\n",
      "it: 5910  | loss 4.53  | Δw: 7.539\n",
      "it: 5920  | loss 4.55  | Δw: 7.447\n",
      "it: 5930  | loss 4.58  | Δw: 7.398\n",
      "it: 5940  | loss 4.49  | Δw: 7.44\n",
      "it: 5950  | loss 4.63  | Δw: 7.546\n",
      "it: 5960  | loss 4.64  | Δw: 7.709\n",
      "it: 5970  | loss 4.63  | Δw: 7.288\n",
      "it: 5980  | loss 4.62  | Δw: 7.877\n",
      "it: 5990  | loss 4.5  | Δw: 7.544\n",
      "it: 6000  | loss 4.65  | Δw: 7.669\n",
      "it: 6010  | loss 4.66  | Δw: 7.613\n",
      "it: 6020  | loss 4.59  | Δw: 7.8\n",
      "it: 6030  | loss 4.57  | Δw: 7.512\n",
      "it: 6040  | loss 4.46  | Δw: 7.779\n",
      "it: 6050  | loss 4.56  | Δw: 7.637\n",
      "it: 6060  | loss 4.62  | Δw: 7.767\n",
      "it: 6070  | loss 4.61  | Δw: 7.615\n",
      "it: 6080  | loss 4.58  | Δw: 7.652\n",
      "it: 6090  | loss 4.57  | Δw: 7.734\n",
      "it: 6100  | loss 4.57  | Δw: 7.313\n",
      "it: 6110  | loss 4.46  | Δw: 7.605\n",
      "it: 6120  | loss 4.52  | Δw: 7.542\n",
      "it: 6130  | loss 4.58  | Δw: 7.533\n",
      "it: 6140  | loss 4.58  | Δw: 7.504\n",
      "it: 6150  | loss 4.47  | Δw: 7.441\n",
      "it: 6160  | loss 4.69  | Δw: 7.487\n",
      "it: 6170  | loss 4.65  | Δw: 7.434\n",
      "it: 6180  | loss 4.54  | Δw: 7.339\n",
      "it: 6190  | loss 4.54  | Δw: 7.665\n",
      "it: 6200  | loss 4.6  | Δw: 7.708\n",
      "it: 6210  | loss 4.61  | Δw: 7.779\n",
      "it: 6220  | loss 4.58  | Δw: 7.414\n",
      "it: 6230  | loss 4.61  | Δw: 7.438\n",
      "it: 6240  | loss 4.48  | Δw: 7.847\n",
      "it: 6250  | loss 4.69  | Δw: 7.495\n",
      "it: 6260  | loss 4.53  | Δw: 7.629\n",
      "it: 6270  | loss 4.58  | Δw: 7.931\n",
      "it: 6280  | loss 4.53  | Δw: 7.523\n",
      "it: 6290  | loss 4.59  | Δw: 7.668\n",
      "it: 6300  | loss 4.62  | Δw: 7.825\n",
      "it: 6310  | loss 4.54  | Δw: 7.496\n",
      "it: 6320  | loss 4.67  | Δw: 7.545\n",
      "it: 6330  | loss 4.61  | Δw: 7.676\n",
      "it: 6340  | loss 4.64  | Δw: 7.824\n",
      "it: 6350  | loss 4.59  | Δw: 7.532\n",
      "it: 6360  | loss 4.61  | Δw: 7.999\n",
      "it: 6370  | loss 4.44  | Δw: 7.978\n",
      "it: 6380  | loss 4.46  | Δw: 7.56\n",
      "it: 6390  | loss 4.53  | Δw: 7.976\n",
      "it: 6400  | loss 4.5  | Δw: 7.655\n",
      "it: 6410  | loss 4.5  | Δw: 7.809\n",
      "it: 6420  | loss 4.41  | Δw: 7.957\n",
      "it: 6430  | loss 4.51  | Δw: 7.568\n",
      "it: 6440  | loss 4.55  | Δw: 7.524\n",
      "it: 6450  | loss 4.47  | Δw: 7.479\n",
      "it: 6460  | loss 4.61  | Δw: 8.005\n",
      "it: 6470  | loss 4.42  | Δw: 7.88\n",
      "it: 6480  | loss 4.55  | Δw: 7.845\n",
      "it: 6490  | loss 4.61  | Δw: 7.942\n",
      "it: 6500  | loss 4.38  | Δw: 7.998\n",
      "it: 6510  | loss 4.55  | Δw: 8.088\n",
      "it: 6520  | loss 4.51  | Δw: 7.892\n",
      "it: 6530  | loss 4.41  | Δw: 8.223\n",
      "it: 6540  | loss 4.47  | Δw: 7.602\n",
      "it: 6550  | loss 4.56  | Δw: 7.863\n",
      "it: 6560  | loss 4.61  | Δw: 7.841\n",
      "it: 6570  | loss 4.61  | Δw: 7.798\n",
      "it: 6580  | loss 4.5  | Δw: 8.205\n",
      "it: 6590  | loss 4.5  | Δw: 8.149\n",
      "it: 6600  | loss 4.43  | Δw: 7.782\n",
      "it: 6610  | loss 4.62  | Δw: 7.706\n",
      "it: 6620  | loss 4.62  | Δw: 7.952\n",
      "it: 6630  | loss 4.52  | Δw: 8.295\n",
      "it: 6640  | loss 4.53  | Δw: 7.702\n",
      "it: 6650  | loss 4.6  | Δw: 7.745\n",
      "it: 6660  | loss 4.43  | Δw: 7.862\n",
      "it: 6670  | loss 4.53  | Δw: 7.718\n",
      "it: 6680  | loss 4.61  | Δw: 7.843\n",
      "it: 6690  | loss 4.48  | Δw: 7.764\n",
      "it: 6700  | loss 4.59  | Δw: 7.961\n",
      "it: 6710  | loss 4.49  | Δw: 8.008\n",
      "it: 6720  | loss 4.48  | Δw: 7.86\n",
      "it: 6730  | loss 4.53  | Δw: 8.205\n",
      "it: 6740  | loss 4.5  | Δw: 7.779\n",
      "it: 6750  | loss 4.46  | Δw: 7.774\n",
      "it: 6760  | loss 4.54  | Δw: 8.056\n",
      "it: 6770  | loss 4.42  | Δw: 8.188\n",
      "it: 6780  | loss 4.46  | Δw: 8.055\n",
      "it: 6790  | loss 4.48  | Δw: 8.133\n",
      "it: 6800  | loss 4.55  | Δw: 8.14\n",
      "it: 6810  | loss 4.47  | Δw: 8.148\n",
      "it: 6820  | loss 4.49  | Δw: 8.021\n",
      "it: 6830  | loss 4.55  | Δw: 7.877\n",
      "it: 6840  | loss 4.5  | Δw: 8.208\n",
      "it: 6850  | loss 4.46  | Δw: 7.99\n",
      "it: 6860  | loss 4.42  | Δw: 8.433\n",
      "it: 6870  | loss 4.49  | Δw: 8.012\n",
      "it: 6880  | loss 4.49  | Δw: 8.228\n",
      "it: 6890  | loss 4.41  | Δw: 8.07\n",
      "it: 6900  | loss 4.47  | Δw: 8.248\n",
      "it: 6910  | loss 4.54  | Δw: 8.345\n",
      "it: 6920  | loss 4.52  | Δw: 8.079\n",
      "it: 6930  | loss 4.48  | Δw: 8.249\n",
      "it: 6940  | loss 4.54  | Δw: 8.339\n",
      "it: 6950  | loss 4.46  | Δw: 8.031\n",
      "it: 6960  | loss 4.47  | Δw: 8.193\n",
      "it: 6970  | loss 4.59  | Δw: 8.409\n",
      "it: 6980  | loss 4.57  | Δw: 8.105\n",
      "it: 6990  | loss 4.43  | Δw: 8.337\n",
      "it: 7000  | loss 4.5  | Δw: 8.314\n",
      "it: 7010  | loss 4.57  | Δw: 7.814\n",
      "it: 7020  | loss 4.59  | Δw: 8.352\n",
      "it: 7030  | loss 4.53  | Δw: 8.671\n",
      "it: 7040  | loss 4.52  | Δw: 8.467\n",
      "it: 7050  | loss 4.55  | Δw: 8.529\n",
      "it: 7060  | loss 4.43  | Δw: 8.213\n",
      "it: 7070  | loss 4.51  | Δw: 8.075\n",
      "it: 7080  | loss 4.5  | Δw: 8.12\n",
      "it: 7090  | loss 4.59  | Δw: 8.323\n",
      "it: 7100  | loss 4.44  | Δw: 8.244\n",
      "it: 7110  | loss 4.46  | Δw: 8.674\n",
      "it: 7120  | loss 4.57  | Δw: 8.211\n",
      "it: 7130  | loss 4.48  | Δw: 8.551\n",
      "it: 7140  | loss 4.45  | Δw: 8.39\n",
      "it: 7150  | loss 4.39  | Δw: 8.097\n",
      "it: 7160  | loss 4.42  | Δw: 8.369\n",
      "it: 7170  | loss 4.55  | Δw: 8.532\n",
      "it: 7180  | loss 4.43  | Δw: 8.225\n",
      "it: 7190  | loss 4.52  | Δw: 7.87\n",
      "it: 7200  | loss 4.43  | Δw: 8.542\n",
      "it: 7210  | loss 4.48  | Δw: 8.163\n",
      "it: 7220  | loss 4.42  | Δw: 8.367\n",
      "it: 7230  | loss 4.45  | Δw: 8.26\n",
      "it: 7240  | loss 4.61  | Δw: 8.313\n",
      "it: 7250  | loss 4.52  | Δw: 8.515\n",
      "it: 7260  | loss 4.42  | Δw: 8.26\n",
      "it: 7270  | loss 4.42  | Δw: 8.432\n",
      "it: 7280  | loss 4.37  | Δw: 8.394\n",
      "it: 7290  | loss 4.51  | Δw: 8.456\n",
      "it: 7300  | loss 4.36  | Δw: 8.191\n",
      "it: 7310  | loss 4.36  | Δw: 8.26\n",
      "it: 7320  | loss 4.45  | Δw: 8.517\n",
      "it: 7330  | loss 4.4  | Δw: 8.641\n",
      "it: 7340  | loss 4.45  | Δw: 8.357\n",
      "it: 7350  | loss 4.5  | Δw: 8.332\n",
      "it: 7360  | loss 4.45  | Δw: 8.319\n",
      "it: 7370  | loss 4.44  | Δw: 8.414\n",
      "it: 7380  | loss 4.43  | Δw: 8.455\n",
      "it: 7390  | loss 4.45  | Δw: 8.609\n",
      "it: 7400  | loss 4.52  | Δw: 8.802\n",
      "it: 7410  | loss 4.49  | Δw: 8.556\n",
      "it: 7420  | loss 4.38  | Δw: 8.36\n",
      "it: 7430  | loss 4.42  | Δw: 8.451\n",
      "it: 7440  | loss 4.5  | Δw: 8.671\n",
      "it: 7450  | loss 4.41  | Δw: 8.466\n",
      "it: 7460  | loss 4.39  | Δw: 8.469\n",
      "it: 7470  | loss 4.48  | Δw: 8.919\n",
      "it: 7480  | loss 4.44  | Δw: 8.465\n",
      "it: 7490  | loss 4.44  | Δw: 8.618\n",
      "it: 7500  | loss 4.55  | Δw: 8.326\n",
      "it: 7510  | loss 4.34  | Δw: 8.486\n",
      "it: 7520  | loss 4.43  | Δw: 8.889\n",
      "it: 7530  | loss 4.4  | Δw: 8.89\n",
      "it: 7540  | loss 4.35  | Δw: 8.74\n",
      "it: 7550  | loss 4.38  | Δw: 8.737\n",
      "it: 7560  | loss 4.37  | Δw: 8.758\n",
      "it: 7570  | loss 4.44  | Δw: 8.467\n",
      "it: 7580  | loss 4.34  | Δw: 8.77\n",
      "it: 7590  | loss 4.52  | Δw: 8.906\n",
      "it: 7600  | loss 4.54  | Δw: 8.869\n",
      "it: 7610  | loss 4.43  | Δw: 8.906\n",
      "it: 7620  | loss 4.43  | Δw: 9.289\n",
      "it: 7630  | loss 4.48  | Δw: 8.816\n",
      "it: 7640  | loss 4.34  | Δw: 8.791\n",
      "it: 7650  | loss 4.41  | Δw: 8.761\n",
      "it: 7660  | loss 4.31  | Δw: 8.991\n",
      "it: 7670  | loss 4.45  | Δw: 8.777\n",
      "it: 7680  | loss 4.39  | Δw: 8.844\n",
      "it: 7690  | loss 4.49  | Δw: 8.811\n",
      "it: 7700  | loss 4.35  | Δw: 8.586\n",
      "it: 7710  | loss 4.43  | Δw: 8.829\n",
      "it: 7720  | loss 4.34  | Δw: 9.032\n",
      "it: 7730  | loss 4.32  | Δw: 8.719\n",
      "it: 7740  | loss 4.38  | Δw: 8.682\n",
      "it: 7750  | loss 4.42  | Δw: 8.79\n",
      "it: 7760  | loss 4.38  | Δw: 9.013\n",
      "it: 7770  | loss 4.38  | Δw: 8.639\n",
      "it: 7780  | loss 4.36  | Δw: 8.839\n",
      "it: 7790  | loss 4.34  | Δw: 8.767\n",
      "it: 7800  | loss 4.38  | Δw: 8.905\n",
      "it: 7810  | loss 4.41  | Δw: 8.696\n",
      "it: 7820  | loss 4.36  | Δw: 8.887\n",
      "it: 7830  | loss 4.39  | Δw: 8.756\n",
      "it: 7840  | loss 4.52  | Δw: 9.026\n",
      "it: 7850  | loss 4.39  | Δw: 9.22\n",
      "it: 7860  | loss 4.47  | Δw: 9.027\n",
      "it: 7870  | loss 4.44  | Δw: 8.939\n",
      "it: 7880  | loss 4.29  | Δw: 9.06\n",
      "it: 7890  | loss 4.48  | Δw: 9.158\n",
      "it: 7900  | loss 4.44  | Δw: 8.727\n",
      "it: 7910  | loss 4.35  | Δw: 8.934\n",
      "it: 7920  | loss 4.37  | Δw: 9.162\n",
      "it: 7930  | loss 4.31  | Δw: 8.966\n",
      "it: 7940  | loss 4.49  | Δw: 9.004\n",
      "it: 7950  | loss 4.37  | Δw: 8.954\n",
      "it: 7960  | loss 4.34  | Δw: 9.266\n",
      "it: 7970  | loss 4.29  | Δw: 9.14\n",
      "it: 7980  | loss 4.5  | Δw: 9.165\n",
      "it: 7990  | loss 4.4  | Δw: 9.014\n",
      "it: 8000  | loss 4.37  | Δw: 9.22\n",
      "it: 8010  | loss 4.4  | Δw: 9.129\n",
      "it: 8020  | loss 4.35  | Δw: 8.757\n",
      "it: 8030  | loss 4.27  | Δw: 9.078\n",
      "it: 8040  | loss 4.44  | Δw: 9.175\n",
      "it: 8050  | loss 4.36  | Δw: 9.41\n",
      "it: 8060  | loss 4.4  | Δw: 9.293\n",
      "it: 8070  | loss 4.41  | Δw: 8.946\n",
      "it: 8080  | loss 4.44  | Δw: 9.559\n",
      "it: 8090  | loss 4.41  | Δw: 9.403\n",
      "it: 8100  | loss 4.34  | Δw: 9.427\n",
      "it: 8110  | loss 4.27  | Δw: 9.013\n",
      "it: 8120  | loss 4.45  | Δw: 9.868\n",
      "it: 8130  | loss 4.42  | Δw: 9.215\n",
      "it: 8140  | loss 4.35  | Δw: 9.295\n",
      "it: 8150  | loss 4.43  | Δw: 9.19\n",
      "it: 8160  | loss 4.33  | Δw: 9.408\n",
      "it: 8170  | loss 4.43  | Δw: 9.072\n",
      "it: 8180  | loss 4.35  | Δw: 9.037\n",
      "it: 8190  | loss 4.42  | Δw: 8.952\n",
      "it: 8200  | loss 4.43  | Δw: 9.466\n",
      "it: 8210  | loss 4.32  | Δw: 8.985\n",
      "it: 8220  | loss 4.46  | Δw: 8.84\n",
      "it: 8230  | loss 4.39  | Δw: 9.33\n",
      "it: 8240  | loss 4.47  | Δw: 9.335\n",
      "it: 8250  | loss 4.39  | Δw: 9.03\n",
      "it: 8260  | loss 4.43  | Δw: 9.315\n",
      "it: 8270  | loss 4.42  | Δw: 9.269\n",
      "it: 8280  | loss 4.4  | Δw: 9.196\n",
      "it: 8290  | loss 4.43  | Δw: 9.5\n",
      "it: 8300  | loss 4.39  | Δw: 9.472\n",
      "it: 8310  | loss 4.35  | Δw: 9.296\n",
      "it: 8320  | loss 4.36  | Δw: 9.287\n",
      "it: 8330  | loss 4.39  | Δw: 9.423\n",
      "it: 8340  | loss 4.24  | Δw: 9.601\n",
      "it: 8350  | loss 4.44  | Δw: 9.435\n",
      "it: 8360  | loss 4.27  | Δw: 9.658\n",
      "it: 8370  | loss 4.33  | Δw: 9.319\n",
      "it: 8380  | loss 4.43  | Δw: 9.472\n",
      "it: 8390  | loss 4.33  | Δw: 9.257\n",
      "it: 8400  | loss 4.33  | Δw: 9.59\n",
      "it: 8410  | loss 4.32  | Δw: 9.642\n",
      "it: 8420  | loss 4.44  | Δw: 9.59\n",
      "it: 8430  | loss 4.34  | Δw: 9.312\n",
      "it: 8440  | loss 4.47  | Δw: 9.599\n",
      "it: 8450  | loss 4.33  | Δw: 9.368\n",
      "it: 8460  | loss 4.37  | Δw: 9.618\n",
      "it: 8470  | loss 4.39  | Δw: 9.402\n",
      "it: 8480  | loss 4.39  | Δw: 9.67\n",
      "it: 8490  | loss 4.39  | Δw: 9.27\n",
      "it: 8500  | loss 4.35  | Δw: 9.573\n",
      "it: 8510  | loss 4.38  | Δw: 9.33\n",
      "it: 8520  | loss 4.28  | Δw: 9.394\n",
      "it: 8530  | loss 4.46  | Δw: 9.692\n",
      "it: 8540  | loss 4.38  | Δw: 9.623\n",
      "it: 8550  | loss 4.31  | Δw: 9.306\n",
      "it: 8560  | loss 4.4  | Δw: 9.891\n",
      "it: 8570  | loss 4.32  | Δw: 9.561\n",
      "it: 8580  | loss 4.37  | Δw: 9.602\n",
      "it: 8590  | loss 4.3  | Δw: 9.697\n",
      "it: 8600  | loss 4.31  | Δw: 9.615\n",
      "it: 8610  | loss 4.23  | Δw: 9.668\n",
      "it: 8620  | loss 4.41  | Δw: 9.551\n",
      "it: 8630  | loss 4.35  | Δw: 9.688\n",
      "it: 8640  | loss 4.32  | Δw: 9.711\n",
      "it: 8650  | loss 4.24  | Δw: 9.369\n",
      "it: 8660  | loss 4.41  | Δw: 9.769\n",
      "it: 8670  | loss 4.41  | Δw: 9.717\n",
      "it: 8680  | loss 4.29  | Δw: 10.034\n",
      "it: 8690  | loss 4.44  | Δw: 9.883\n",
      "it: 8700  | loss 4.33  | Δw: 10.14\n",
      "it: 8710  | loss 4.39  | Δw: 9.954\n",
      "it: 8720  | loss 4.37  | Δw: 9.749\n",
      "it: 8730  | loss 4.43  | Δw: 9.778\n",
      "it: 8740  | loss 4.28  | Δw: 9.696\n",
      "it: 8750  | loss 4.35  | Δw: 9.802\n",
      "it: 8760  | loss 4.34  | Δw: 9.482\n",
      "it: 8770  | loss 4.28  | Δw: 9.969\n",
      "it: 8780  | loss 4.33  | Δw: 10.143\n",
      "it: 8790  | loss 4.44  | Δw: 9.791\n",
      "it: 8800  | loss 4.46  | Δw: 9.442\n",
      "it: 8810  | loss 4.28  | Δw: 9.775\n",
      "it: 8820  | loss 4.3  | Δw: 9.997\n",
      "it: 8830  | loss 4.3  | Δw: 9.645\n",
      "it: 8840  | loss 4.32  | Δw: 9.658\n",
      "it: 8850  | loss 4.43  | Δw: 10.271\n",
      "it: 8860  | loss 4.38  | Δw: 9.749\n",
      "it: 8870  | loss 4.35  | Δw: 9.92\n",
      "it: 8880  | loss 4.36  | Δw: 9.729\n",
      "it: 8890  | loss 4.3  | Δw: 9.733\n",
      "it: 8900  | loss 4.34  | Δw: 9.793\n",
      "it: 8910  | loss 4.26  | Δw: 9.853\n",
      "it: 8920  | loss 4.3  | Δw: 10.176\n",
      "it: 8930  | loss 4.3  | Δw: 9.677\n",
      "it: 8940  | loss 4.24  | Δw: 10.016\n",
      "it: 8950  | loss 4.38  | Δw: 10.114\n",
      "it: 8960  | loss 4.24  | Δw: 9.677\n",
      "it: 8970  | loss 4.32  | Δw: 10.435\n",
      "it: 8980  | loss 4.28  | Δw: 9.731\n",
      "it: 8990  | loss 4.4  | Δw: 10.157\n",
      "it: 9000  | loss 4.39  | Δw: 9.748\n",
      "it: 9010  | loss 4.32  | Δw: 9.98\n",
      "it: 9020  | loss 4.37  | Δw: 9.982\n",
      "it: 9030  | loss 4.3  | Δw: 9.629\n",
      "it: 9040  | loss 4.39  | Δw: 9.99\n",
      "it: 9050  | loss 4.37  | Δw: 10.19\n",
      "it: 9060  | loss 4.32  | Δw: 9.864\n",
      "it: 9070  | loss 4.28  | Δw: 9.823\n",
      "it: 9080  | loss 4.24  | Δw: 10.195\n",
      "it: 9090  | loss 4.43  | Δw: 9.897\n",
      "it: 9100  | loss 4.28  | Δw: 10.023\n",
      "it: 9110  | loss 4.3  | Δw: 9.892\n",
      "it: 9120  | loss 4.27  | Δw: 10.507\n",
      "it: 9130  | loss 4.31  | Δw: 10.276\n",
      "it: 9140  | loss 4.3  | Δw: 10.021\n",
      "it: 9150  | loss 4.27  | Δw: 10.208\n",
      "it: 9160  | loss 4.32  | Δw: 10.072\n",
      "it: 9170  | loss 4.41  | Δw: 9.971\n",
      "it: 9180  | loss 4.26  | Δw: 10.255\n",
      "it: 9190  | loss 4.32  | Δw: 9.885\n",
      "it: 9200  | loss 4.33  | Δw: 9.761\n",
      "it: 9210  | loss 4.29  | Δw: 10.063\n",
      "it: 9220  | loss 4.39  | Δw: 9.775\n",
      "it: 9230  | loss 4.28  | Δw: 10.524\n",
      "it: 9240  | loss 4.32  | Δw: 9.885\n",
      "it: 9250  | loss 4.33  | Δw: 10.133\n",
      "it: 9260  | loss 4.37  | Δw: 10.179\n",
      "it: 9270  | loss 4.37  | Δw: 10.422\n",
      "it: 9280  | loss 4.28  | Δw: 10.026\n",
      "it: 9290  | loss 4.42  | Δw: 10.215\n",
      "it: 9300  | loss 4.38  | Δw: 10.179\n",
      "it: 9310  | loss 4.37  | Δw: 9.936\n",
      "it: 9320  | loss 4.38  | Δw: 10.363\n",
      "it: 9330  | loss 4.2  | Δw: 10.202\n",
      "it: 9340  | loss 4.29  | Δw: 10.608\n",
      "it: 9350  | loss 4.22  | Δw: 10.397\n",
      "it: 9360  | loss 4.32  | Δw: 9.967\n",
      "it: 9370  | loss 4.37  | Δw: 10.358\n",
      "it: 9380  | loss 4.28  | Δw: 10.112\n",
      "it: 9390  | loss 4.32  | Δw: 9.952\n",
      "it: 9400  | loss 4.24  | Δw: 10.33\n",
      "it: 9410  | loss 4.26  | Δw: 10.293\n",
      "it: 9420  | loss 4.26  | Δw: 10.375\n",
      "it: 9430  | loss 4.35  | Δw: 10.311\n",
      "it: 9440  | loss 4.24  | Δw: 10.258\n",
      "it: 9450  | loss 4.29  | Δw: 10.39\n",
      "it: 9460  | loss 4.29  | Δw: 10.618\n",
      "it: 9470  | loss 4.31  | Δw: 10.631\n",
      "it: 9480  | loss 4.19  | Δw: 10.732\n",
      "it: 9490  | loss 4.28  | Δw: 10.477\n",
      "it: 9500  | loss 4.38  | Δw: 10.384\n",
      "it: 9510  | loss 4.38  | Δw: 10.502\n",
      "it: 9520  | loss 4.3  | Δw: 10.21\n",
      "it: 9530  | loss 4.26  | Δw: 10.284\n",
      "it: 9540  | loss 4.23  | Δw: 10.484\n",
      "it: 9550  | loss 4.44  | Δw: 10.714\n",
      "it: 9560  | loss 4.35  | Δw: 10.666\n",
      "it: 9570  | loss 4.23  | Δw: 11.243\n",
      "it: 9580  | loss 4.32  | Δw: 10.591\n",
      "it: 9590  | loss 4.35  | Δw: 10.593\n",
      "it: 9600  | loss 4.25  | Δw: 10.483\n",
      "it: 9610  | loss 4.33  | Δw: 10.806\n",
      "it: 9620  | loss 4.31  | Δw: 11.006\n",
      "it: 9630  | loss 4.24  | Δw: 10.887\n",
      "it: 9640  | loss 4.11  | Δw: 10.784\n",
      "it: 9650  | loss 4.29  | Δw: 10.579\n",
      "it: 9660  | loss 4.14  | Δw: 11.013\n",
      "it: 9670  | loss 4.25  | Δw: 10.396\n",
      "it: 9680  | loss 4.26  | Δw: 10.185\n",
      "it: 9690  | loss 4.26  | Δw: 10.675\n",
      "it: 9700  | loss 4.22  | Δw: 10.597\n",
      "it: 9710  | loss 4.22  | Δw: 10.691\n",
      "it: 9720  | loss 4.21  | Δw: 10.64\n",
      "it: 9730  | loss 4.21  | Δw: 10.973\n",
      "it: 9740  | loss 4.19  | Δw: 10.94\n",
      "it: 9750  | loss 4.3  | Δw: 10.585\n",
      "it: 9760  | loss 4.3  | Δw: 10.806\n",
      "it: 9770  | loss 4.24  | Δw: 10.552\n",
      "it: 9780  | loss 4.2  | Δw: 10.316\n",
      "it: 9790  | loss 4.16  | Δw: 10.764\n",
      "it: 9800  | loss 4.32  | Δw: 10.702\n",
      "it: 9810  | loss 4.26  | Δw: 10.688\n",
      "it: 9820  | loss 4.29  | Δw: 11.196\n",
      "it: 9830  | loss 4.24  | Δw: 10.59\n",
      "it: 9840  | loss 4.17  | Δw: 11.069\n",
      "it: 9850  | loss 4.23  | Δw: 10.588\n",
      "it: 9860  | loss 4.18  | Δw: 10.477\n",
      "it: 9870  | loss 4.28  | Δw: 10.701\n",
      "it: 9880  | loss 4.28  | Δw: 11.541\n",
      "it: 9890  | loss 4.31  | Δw: 10.843\n",
      "it: 9900  | loss 4.21  | Δw: 11.241\n",
      "it: 9910  | loss 4.38  | Δw: 10.666\n",
      "it: 9920  | loss 4.2  | Δw: 10.593\n",
      "it: 9930  | loss 4.32  | Δw: 11.114\n",
      "it: 9940  | loss 4.24  | Δw: 11.764\n",
      "it: 9950  | loss 4.31  | Δw: 10.956\n",
      "it: 9960  | loss 4.19  | Δw: 11.007\n",
      "it: 9970  | loss 4.14  | Δw: 11.185\n",
      "it: 9980  | loss 4.2  | Δw: 10.817\n",
      "it: 9990  | loss 4.22  | Δw: 11.011\n",
      "saving embeddings...\n",
      "end\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "#init model\n",
    "print('initializing model...')\n",
    "model = Transformer(n_code=n_code, n_heads=n_heads, embed_size=embed_size, inner_ff_size=inner_ff_size, n_embeddings=len(dataset.vocab), seq_len=seq_len, dropout=dropout)\n",
    "model = model.cuda()\n",
    "\n",
    "# =============================================================================\n",
    "# Optimizer\n",
    "# =============================================================================\n",
    "print('initializing optimizer and loss...')\n",
    "optimizer = optim.Adam(model.parameters(), **optim_kwargs)\n",
    "loss_model = nn.CrossEntropyLoss(ignore_index=dataset.IGNORE_IDX)\n",
    "\n",
    "# =============================================================================\n",
    "# Train\n",
    "# =============================================================================\n",
    "print('training...')\n",
    "print_each = 10\n",
    "model.train()\n",
    "batch_iter = iter(data_loader)\n",
    "n_iteration = 10000\n",
    "for it in range(n_iteration):\n",
    "\n",
    "    #get batch\n",
    "    batch, batch_iter = get_batch(data_loader, batch_iter)\n",
    "\n",
    "    #infer\n",
    "    masked_input = batch['input']\n",
    "    masked_target = batch['target']\n",
    "\n",
    "    masked_input = masked_input.cuda(non_blocking=True)\n",
    "    masked_target = masked_target.cuda(non_blocking=True)\n",
    "    output = model(masked_input)\n",
    "\n",
    "    #compute the cross entropy loss\n",
    "    output_v = output.view(-1,output.shape[-1])\n",
    "    target_v = masked_target.view(-1,1).squeeze()\n",
    "    loss = loss_model(output_v, target_v)\n",
    "\n",
    "    #compute gradients\n",
    "    loss.backward()\n",
    "\n",
    "    #apply gradients\n",
    "    optimizer.step()\n",
    "\n",
    "    #print step\n",
    "    if it % print_each == 0:\n",
    "        print('it:', it,\n",
    "              ' | loss', np.round(loss.item(),2),\n",
    "              ' | Δw:', round(model.embeddings.weight.grad.abs().sum().item(),3))\n",
    "\n",
    "    #reset gradients\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# Results analysis\n",
    "# =============================================================================\n",
    "print('saving embeddings...')\n",
    "N = 3000\n",
    "np.savetxt('values.tsv', np.round(model.embeddings.weight.detach().cpu().numpy()[0:N], 2), delimiter='\\t', fmt='%1.2f')\n",
    "s = [dataset.rvocab[i] for i in range(N)]\n",
    "open('names.tsv', 'w+').write('\\n'.join(s) )\n",
    "\n",
    "\n",
    "print('end')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "era",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
